{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMMjo25o1QeOVJBGauU1cL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishna324-art/LLM-from-Scratch-/blob/main/Datapreparation_and_sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Mjy3zoV5uK0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f41ce6f9-8811-43d5-b0ec-c5158d482350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of characters: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/the-verdict.txt\",\"r\",encoding=\"utf-8\")as f:\n",
        "  raw_text=f.read()\n",
        "print(\"Total Number of characters:\",len(raw_text))\n",
        "print(raw_text[:99])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#goal is to tokenize this 20479\n",
        "import re\n",
        "text= \"Hello, world. This, is a test.\"\n",
        "result=re.split(r'(\\s)',text)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2Udase1sjPq",
        "outputId": "ee84a870-182c-4ecf-a887-8c9f2aacbd3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to split commas and periods\n",
        "results=re.split(r'([,.]|\\s)',text)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob_YnR4KutWC",
        "outputId": "33c7eb0d-3936-4ba6-b413-6998a183bf23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to remove white space characters\n",
        "results1=[item for item in results if item.strip()]\n",
        "print(results1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II_TSV9ivtRi",
        "outputId": "e6e6140b-63f3-4efc-92cf-6334086fb062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Hello, world. Is this-- a test?\"\n",
        "results= re.split(r'([,.:;?_!\"()\\']|--|\\s)',text)\n",
        "results=[item.strip()for item in results if item.strip()]\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq38OKX8wj8L",
        "outputId": "6a69245d-1bf3-474c-8fd5-8954e82aebac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#strip out whitespace from each item and then filter out any empty string\n",
        "result=[item for item in results if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj94hPSfyEgd",
        "outputId": "6a3233b3-3cc7-49fc-96ba-1f5f5f514045"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed= re.split(r'([,.:;?_!\"()\\']|--|\\s)',raw_text)\n",
        "preprocessed=[item.strip() for item in preprocessed if item.strip()]\n",
        "print(preprocessed[:30])"
      ],
      "metadata": {
        "id": "9cpX9_ZDzYdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c9aa37e-b988-4628-ab27-66780cf1934f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(preprocessed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_4WN0lqZnPa",
        "outputId": "8844c93f-eb1f-42d5-cd82-00b650644e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating token id\n",
        "all_words=sorted(set(preprocessed))\n",
        "vocab_size= len(all_words)\n",
        "print(vocab_size)#vocab size has all unique words only"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qEeDqxlZ2yw",
        "outputId": "7426ca31-a75b-4bc6-f9de-83b415b11073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab={token:integer for integer,token in enumerate(all_words)}\n",
        "for i ,item in enumerate(vocab.items()):\n",
        "  print(item)\n",
        "  if i>=50:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iQiS44scPXt",
        "outputId": "d8df5f36-2c0e-4814-b427-0a2c058eea00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "(':', 8)\n",
            "(';', 9)\n",
            "('?', 10)\n",
            "('A', 11)\n",
            "('Ah', 12)\n",
            "('Among', 13)\n",
            "('And', 14)\n",
            "('Are', 15)\n",
            "('Arrt', 16)\n",
            "('As', 17)\n",
            "('At', 18)\n",
            "('Be', 19)\n",
            "('Begin', 20)\n",
            "('Burlington', 21)\n",
            "('But', 22)\n",
            "('By', 23)\n",
            "('Carlo', 24)\n",
            "('Chicago', 25)\n",
            "('Claude', 26)\n",
            "('Come', 27)\n",
            "('Croft', 28)\n",
            "('Destroyed', 29)\n",
            "('Devonshire', 30)\n",
            "('Don', 31)\n",
            "('Dubarry', 32)\n",
            "('Emperors', 33)\n",
            "('Florence', 34)\n",
            "('For', 35)\n",
            "('Gallery', 36)\n",
            "('Gideon', 37)\n",
            "('Gisburn', 38)\n",
            "('Gisburns', 39)\n",
            "('Grafton', 40)\n",
            "('Greek', 41)\n",
            "('Grindle', 42)\n",
            "('Grindles', 43)\n",
            "('HAD', 44)\n",
            "('Had', 45)\n",
            "('Hang', 46)\n",
            "('Has', 47)\n",
            "('He', 48)\n",
            "('Her', 49)\n",
            "('Hermia', 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Simpletokenizerv1:\n",
        "  def __init__(self,vocab):\n",
        "    self.str_to_int= vocab\n",
        "    self.int_to_str={i:s for s,i in vocab.items()}\n",
        "\n",
        "  def encode(self,text):\n",
        "    preprocessed= re.split(r'([,.:;?_!\"()\\']|--|\\s)',text)\n",
        "    preprocessed= [item.strip() for item in preprocessed if item.strip()]\n",
        "    ids=[self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        "  def decode(self,ids):\n",
        "    text=\" \".join([self.int_to_str[i] for i in ids])\n",
        "    #replace spaces before the specified punctuations\n",
        "    text=re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "twQanqurdSFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer= Simpletokenizerv1(vocab)\n",
        "text= \"\"\"\"It's the last he painted, you know,\"\n",
        "         Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "\n",
        "ids= tokenizer.encode(text)\n",
        "print(ids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxY_trrpzQws",
        "outputId": "ad0e2f67-1b63-46e9-9364-b31dc27f2c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Bb5cpiyZ0o8-",
        "outputId": "e96b4468-5401-442a-9d31-a51dce8c7d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#add a special context tokens\n",
        "all_tokens= sorted(list(set(preprocessed)))\n",
        "all_tokens.extend([\"<|endoftext|>\",\"<|unk|>\"])\n",
        "vocab={token:integer for integer,token in enumerate(all_tokens)}"
      ],
      "metadata": {
        "id": "bE3ZGnLg055X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7MCJ70BH9YR",
        "outputId": "ceb34829-687b-4162-f0b4-37d35fce9887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1132"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the last 5 items in the vocab dictionary\n",
        "for i, item in enumerate(list(vocab.items())[-5:]):\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd7gFri0IDdh",
        "outputId": "49061bcb-3055-40da-e1c7-09ec839ad2b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('younger', 1127)\n",
            "('your', 1128)\n",
            "('yourself', 1129)\n",
            "('<|endoftext|>', 1130)\n",
            "('<|unk|>', 1131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpletokenizerV2:\n",
        " def __init__(self,vocab):\n",
        "    self.str_to_int= vocab\n",
        "    self.int_to_str={i:s for s,i in vocab.items()}\n",
        "\n",
        " def encode(self,text):\n",
        "    preprocessed= re.split(r'([,.:;?_!\"()\\']|--|\\s)',text)\n",
        "    preprocessed= [item.strip() for item in preprocessed if item.strip()]\n",
        "    preprocessed=[\n",
        "        item if item in self.str_to_int\n",
        "        else \"<|unk|>\" for item in preprocessed\n",
        "    ]\n",
        "    ids=[self.str_to_int[s] for s in preprocessed]\n",
        "    return ids\n",
        "\n",
        " def decode(self,ids):\n",
        "    text=\" \".join([self.int_to_str[i] for i in ids])\n",
        "    #replace spaces before the specified punctuations\n",
        "    text=re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "    return text\n",
        "\n"
      ],
      "metadata": {
        "id": "MHugaTqkInBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=SimpletokenizerV2(vocab)\n",
        "text1=\"Hello, do you like tea?\"\n",
        "text2=\"In the sunlit terraces of the palace.\"\n",
        "text=\" <|endoftext|> \".join((text1,text2))\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhqx5XjbVYNI",
        "outputId": "ff0cedce-a391-4956-bf77-209fd1887c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCaHRt92aM_1",
        "outputId": "61a1203a-64b1-4937-927f-a8e4a6c9bd7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(tokenizer.encode(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "TtZFcqUabxn_",
        "outputId": "4c010d40-d1ff-4f66-c97c-1a896b97ea94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BPE\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "gzayFXX5dwFw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05cc2d27-59ac-4a4d-a5b2-029b053f807c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import tiktoken\n",
        "print(\"tiktoken version:\",importlib.metadata.version(\"tiktoken\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBtZlApAgqlU",
        "outputId": "3d97fa43-5a36-4b7b-9054-2769180b36fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer= tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "EM_Iqachg--O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=(\n",
        "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
        "    \"of someunknownPlace.\"\n",
        ")\n",
        "integers= tokenizer.encode(text,allowed_special={\"<|endoftext|>\"})\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd5xOlnAiCOM",
        "outputId": "aa543ce7-cacd-4407-ddfc-fcfa5bb1b7c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings= tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYT5T1gLjP7D",
        "outputId": "7ff40792-9d0b-4ef4-e6e4-e7a1444c76b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "integrs= tokenizer.encode(\"Akwirw ier\")\n",
        "print(integrs)\n",
        "strings= tokenizer.decode(integrs)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df-7VTiWjwJt",
        "outputId": "61e288ef-fd49-46f1-9542-9925e6f94127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33901, 86, 343, 86, 220, 959]\n",
            "Akwirw ier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#input target pairs\n",
        "with open(\"/content/the-verdict.txt\",\"r\",encoding=\"utf-8\")as f:\n",
        "  raw_text=f.read()\n",
        "enc_text= tokenizer.encode(raw_text)\n",
        "print(len(enc_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2eseBeCmFNE",
        "outputId": "b183fda6-9d12-4453-eaa2-973c2d6f0ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample=enc_text[50:]"
      ],
      "metadata": {
        "id": "R2UAagR5R2yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_size=4 #length of the input\n",
        "x= enc_sample[:context_size]\n",
        "y=enc_sample[1:context_size+1]\n",
        "print(f\"x:{x}\")\n",
        "print(f\"y:{y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJHJwDSWUtVO",
        "outputId": "ff7bb47c-813b-4eb8-c63a-e22876d2bae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:[290, 4920, 2241, 287]\n",
            "y:[4920, 2241, 287, 257]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#processing the inputs along with the targets\n",
        "for i in range(1,context_size+1):\n",
        "  context= enc_sample[:i]\n",
        "  desired= enc_sample[i]\n",
        "  print(context,\"---->\",desired)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lf2cIXhGvTy",
        "outputId": "35b9c413-3589-49b5-a906-36dc201aec51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290] ----> 4920\n",
            "[290, 4920] ----> 2241\n",
            "[290, 4920, 2241] ----> 287\n",
            "[290, 4920, 2241, 287] ----> 257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,context_size+1):\n",
        "  context= enc_sample[:i]\n",
        "  desired= enc_sample[i]\n",
        "  print(tokenizer.decode(context),\"---->\",tokenizer.decode([desired]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC8wOY5ZHmm4",
        "outputId": "e934d419-f586-4206-a971-769b5a0f6f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " and ---->  established\n",
            " and established ---->  himself\n",
            " and established himself ---->  in\n",
            " and established himself in ---->  a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#implementing data loader\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class GPTdatasetV1(Dataset):\n",
        "  def __init__(self,txt,tokenizer,max_length,stride):\n",
        "    self.input_ids=[]\n",
        "    self.target_ids=[]\n",
        "\n",
        "    #tokenize the entire text\n",
        "    token_ids=tokenizer.encode(txt,allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "    #use a sliding window to chunk the book into overlapping sequence of max_legth\n",
        "    for i in range(0,len(token_ids)- max_length,stride):\n",
        "      input_chunk=token_ids[i:i+max_length]\n",
        "      target_chunk= token_ids[i+1: i+max_length +1]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    return self.input_ids[idx],self.target_ids[idx]"
      ],
      "metadata": {
        "id": "ev0upzwNKCWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt,batch_size=4, max_length=256,\n",
        "                         stride=128,shuffle=True,drop_last=True,\n",
        "                         num_workers=0):\n",
        "  #initialize the tokenizer\n",
        "  tokenizer= tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "  #craete dataset\n",
        "  dataset=GPTdatasetV1(txt,tokenizer,max_length,stride)\n",
        "  #create daataloader\n",
        "  dataloader=DataLoader(\n",
        "      dataset,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=shuffle,\n",
        "      drop_last=drop_last,\n",
        "      num_workers=num_workers)\n",
        "  return dataloader\n"
      ],
      "metadata": {
        "id": "dXoevArJTNBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/the-verdict.txt\",\"r\",encoding=\"utf-8\")as f:\n",
        "  raw_text=f.read()"
      ],
      "metadata": {
        "id": "xCWXCh0NW_gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"Pytorch version:\",torch.__version__)\n",
        "dataloader= create_dataloader_v1(raw_text,batch_size=1,max_length=4,stride=1,shuffle=False)\n",
        "data_iter= iter(dataloader)\n",
        "first_batch=next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jseG5bDnblg",
        "outputId": "790a0873-a365-4c58-8741-a84cdf09662a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch version: 2.8.0+cu126\n",
            "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader= create_dataloader_v1(raw_text,batch_size=8,max_length=4,stride=4)\n",
        "data_iter=iter(dataloader)\n",
        "inputs,targets= next(data_iter)\n",
        "print(\"Inputs:\\n\",inputs)\n",
        "print(\"targets:\\n\",targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkTRQsuWopkn",
        "outputId": "cbc37871-b950-408d-c0f4-d6dc9862ce62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[34537,   526,   198,   198],\n",
            "        [  423,  1760,   257,  1049],\n",
            "        [   11,   314,  1422,   470],\n",
            "        [  286,   262, 33125,    12],\n",
            "        [19242,   339,   442, 17758],\n",
            "        [ 6164,    11,  8104,   736],\n",
            "        [ 3896,    11,   262,   661],\n",
            "        [  587,  1498,   284,   910]])\n",
            "targets:\n",
            " tensor([[  526,   198,   198,     1],\n",
            "        [ 1760,   257,  1049,  1517],\n",
            "        [  314,  1422,   470,  1337],\n",
            "        [  262, 33125,    12,   565],\n",
            "        [  339,   442, 17758,   465],\n",
            "        [   11,  8104,   736,   465],\n",
            "        [   11,   262,   661,   508],\n",
            "        [ 1498,   284,   910,   644]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=50257\n",
        "output_dim=256\n",
        "token_embedding_layer=torch.nn.Embedding(vocab_size,output_dim)"
      ],
      "metadata": {
        "id": "ABLkUV8kIe-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data loader\n",
        "#8-batch size,4 context length, 256 dimentional vector\n",
        "#8*4*256 tensor\n",
        "max_length=4\n",
        "dataloader=create_dataloader_v1(raw_text,batch_size=8,max_length=max_length,\n",
        "                                stride=max_length,shuffle=False)\n",
        "data_iter=iter(dataloader)\n",
        "inputs,targets=next(data_iter)"
      ],
      "metadata": {
        "id": "qhMSJetufywl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"token Id:\\n\",inputs)\n",
        "print(\"\\nInputs shape:\\n\",inputs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtKu8Rmbhp3F",
        "outputId": "8605fc67-ba31-4f9f-9589-78b321a0c8e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token Id:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Inputs shape:\n",
            " torch.Size([8, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings=token_embedding_layer(inputs)\n",
        "print(token_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M95v42EPizTN",
        "outputId": "41eae229-37c1-4948-da0c-fafb9f4c07df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length=max_length\n",
        "pos_embedding_layer= torch.nn.Embedding(context_length,output_dim)"
      ],
      "metadata": {
        "id": "x4gCYFZ6j6Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_embedding=pos_embedding_layer(torch.arange(max_length))\n",
        "print(pos_embedding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w43zOzPflKla",
        "outputId": "b5c7d50d-484c-4eb8-c921-b0bf1bba8ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SP2yGFrQlhOt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}